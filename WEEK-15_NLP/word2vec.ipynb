{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "OnfS9P212p_t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# `word2vec` example with `gensim`\n",
        "\n",
        "In this notebook we are going to user the `gensim` library to make operations with word embeddings in spanish. \n",
        "\n",
        "We will download the pre-trained embeddings with Wikipedia text for Spanish from https://github.com/uchile-nlp/spanish-word-embeddings. We select "
      ]
    },
    {
      "metadata": {
        "id": "cyO7DLAY2p_y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gensim, logging, os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6zMUnkoQ2qAx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can load a word2vec model by:"
      ]
    },
    {
      "metadata": {
        "id": "HEdbknxo2qAz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embed_home = 'drive/My Drive/kschool-nlp/data/word-embeddings/'\n",
        "model_file = embed_home + 'SBW-vectors-300-min5.txt.bz2'\n",
        "\n",
        "#model = gensim.models.Word2Vec.load(model_file)\n",
        "model = gensim.models.keyedvectors.Word2VecKeyedVectors.load_word2vec_format(model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l4f6a0Sy2qA2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing the model\n",
        "\n",
        "The object `model` contains an enormous matrix of numbers: a table where each file represents a term in the vocabulary and each column is one of the features that assigns a meaning to that term. \n",
        "\n",
        "In our model we have more than 26M terms. "
      ]
    },
    {
      "metadata": {
        "id": "prXmUJ8i2qA7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each term in the vocabulary is represented with a vector of 150 dimensions. We can see one specific value. "
      ]
    },
    {
      "metadata": {
        "id": "gGrXpcFf2qA8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(model['azul'], '\\n')\n",
        "\n",
        "print(model['verde'], '\\n')\n",
        "\n",
        "print(model['microsoft'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fsdriGoL2qA_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "These vectors don't tell us too much, except that they are small numbers...\n",
        "\n",
        "The object `model` allows us to access a set of functionalities already implemented that will allow us to evaluate (informally) the model. \n",
        "\n",
        "We can compute the semantic similarity between two terms, using method `similarity`, that returns a value between 0 and 1:"
      ]
    },
    {
      "metadata": {
        "id": "z4FCpC7t2qBB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('hombre - mujer', model.similarity('hombre', 'mujer'))\n",
        "\n",
        "print('perro - gato', model.similarity('perro', 'gato'))\n",
        "\n",
        "print('gato - periódico', model.similarity('gato', 'periódico'))\n",
        "\n",
        "print('febrero - azul', model.similarity('febrero', 'azul'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eVCwoBST2qBE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can also select the term that does not fit in a list, using method `doesnt_match`:"
      ]
    },
    {
      "metadata": {
        "id": "J9nhCICS2qBF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lista1 = 'madrid barcelona gonzález washington'.split()\n",
        "print('en la lista', ' '.join(lista1), 'sobra:', model.doesnt_match(lista1))\n",
        "\n",
        "lista2 = 'psoe pp ciu juan'.split()\n",
        "print('en la lista', ' '.join(lista2), 'sobra:', model.doesnt_match(lista2))\n",
        "\n",
        "lista3 = 'publicaron declararon soy negaron'.split()\n",
        "print('en la lista', ' '.join(lista3), 'sobra:', model.doesnt_match(lista3))\n",
        "\n",
        "lista4 = 'homero saturno cervantes shakespeare cela'.split()\n",
        "print('en la lista', ' '.join(lista4), 'sobra:', model.doesnt_match(lista4))\n",
        "\n",
        "lista5 = 'madrid barcelona valencia marsella'.split()\n",
        "print('en la lista', ' '.join(lista5), 'sobra:', model.doesnt_match(lista5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xAgf4OmQ2qBI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can also find the most similar words by using the method `most_similar` in the model:"
      ]
    },
    {
      "metadata": {
        "id": "PX8JFltx2qBJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "terminos = 'psoe chicago rajoy enero amarillo microsoft iberia messi atlético'.split()\n",
        "\n",
        "for t in terminos:\n",
        "    print(t, '==>', model.most_similar(t), '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J-piGWK-2qBM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Furthermore, we can also use the same method `most_similar` to make arithmetic operations with vectors."
      ]
    },
    {
      "metadata": {
        "id": "8gBU4LTw2qBN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('mujer que ejerce la autoridad en una alcaldía ==> alcalde + mujer - hombre')\n",
        "most_similar = model.most_similar(positive=['alcalde', 'mujer'], negative=['hombre'], topn=3)\n",
        "for item in most_similar:\n",
        "    print(item)\n",
        "\n",
        "print('monarca soberano ==> reina + hombre - mujer')    \n",
        "most_similar = model.most_similar(positive=['reina', 'hombre'], negative=['mujer'], topn=3)\n",
        "for item in most_similar:\n",
        "    print(item)\n",
        "    \n",
        "print('capital de Alemania ==> moscú + alemania - rusia')\n",
        "most_similar = model.most_similar(positive=['moscú', 'alemania'], negative=['rusia'], topn=3)\n",
        "for item in most_similar:\n",
        "    print(item)\n",
        "\n",
        "print('presidente de Francia ==> rajoy + francia - españa')\n",
        "most_similar = model.most_similar(positive=['mariano', 'francia'], negative=['españa'], topn=3)\n",
        "for item in most_similar:\n",
        "    print(item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ViSe6iL2qBS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "most_similar = model.most_similar(positive=['obama', 'francia'], negative=['eeuu'], topn=3)\n",
        "for item in most_similar:\n",
        "    print(item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OBBDL0BZ-h_T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}